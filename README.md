Machine Learning Projects – Internship at Digital Empowerment Network

This repository contains the machine learning projects I developed during my internship at Digital Empowerment Network. Each project applies core data science and machine learning concepts to solve real-world problems, from healthcare to real estate and text classification.

The projects demonstrate my ability to perform data preprocessing, exploratory data analysis (EDA), feature engineering, model building, evaluation, and interpretation of results.

📌 Projects
1. Heart Disease Prediction

Objective: Build models to predict whether a patient has heart disease based on clinical data.

Dataset: Publicly available Heart Disease dataset (Kaggle) with 1,025 patient records.

Techniques Used:

Exploratory Data Analysis (heatmaps, boxplots, histograms)

Feature engineering based on correlation analysis

Machine learning models: Logistic Regression, Decision Tree, Random Forest

Hyperparameter tuning for optimization

Results:

Random Forest achieved the highest accuracy (98.54%).

Feature engineering improved model efficiency and performance.

Real-World Use: Can be integrated into hospital systems or telehealth platforms for early disease detection.

2. House Price Prediction

Objective: Predict house prices in popular cities of Pakistan using structured real estate data.

Dataset: Real estate listings from zameen.com.

Methodology:

Data cleaning (handled missing values, transformed inconsistent area units like Marla/Kanal).

Feature engineering (created numerical and categorical features from area, encoded categorical variables).

Models: Linear Regression, Random Forest Regressor, Gradient Boosting Regressor.

Results:

Random Forest and Gradient Boosting outperformed Linear Regression.

Best model achieved R² score of 0.91, showing strong predictive power.

Challenges Solved: Outliers in house prices, inconsistent area formats, and categorical data encoding.

Applications: Useful for buyers, sellers, and real estate agents for accurate property valuation.

3. Email Spam Classification

Objective: Build a text classification model to detect spam emails.

Dataset: Labeled dataset of emails (spam/ham).

Approach:

Preprocessing (lowercasing, removing special characters, tokenization, stopword removal, lemmatization).

Feature extraction using TF-IDF vectorization.

Models: Naive Bayes, Logistic Regression, Support Vector Machine (SVM).

Results:

SVM achieved the highest accuracy (98.7%) with the best balance of precision and recall.

Naive Bayes and Logistic Regression also performed well (>97% accuracy).

Impact: Reliable spam detection reduces user risk by filtering malicious/unwanted emails.

🛠️ Tech Stack

Languages: Python

Libraries & Tools: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn

Techniques Applied:

Data preprocessing & cleaning

Exploratory Data Analysis (EDA)

Feature Engineering

Supervised Learning (Classification & Regression)

Model Evaluation (Accuracy, Precision, Recall, F1-Score, R², MSE)


✅ These projects reflect my growing interest and expertise in data science and machine learning.
